{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, df_test, testing = False):\n",
    "#     df = df.copy()\n",
    "    categories_dict = {}\n",
    "    \n",
    "    temp_merge = df.append(df_test)\n",
    "    for cat in temp_merge.columns:\n",
    "        if temp_merge[cat].dtypes == 'object':\n",
    "            categories_dict[cat] = list(temp_merge[cat].unique())\n",
    "            if testing:\n",
    "                print(\"Numero de categorias para variavel '{}': {} \".format(cat,temp_merge[cat].unique().size))\n",
    "\n",
    "    if testing:\n",
    "        print()\n",
    "        print(list(categories_dict.keys()))\n",
    "        \n",
    "    enc = OrdinalEncoder(categories=list(categories_dict.values()))\n",
    "    trained_encoder = enc.fit(df[list(categories_dict.keys())])\n",
    "    \n",
    "    # transform train and test\n",
    "    df[list(categories_dict.keys())] = trained_encoder.transform(df[list(categories_dict.keys())])\n",
    "    df_test[list(categories_dict.keys())] = trained_encoder.transform(df_test[list(categories_dict.keys())])\n",
    "\n",
    "    if testing:\n",
    "        print(categories_dict)\n",
    "    \n",
    "    return df, df_test\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    print('Quantity of columns before one-hot encoding:', len(df.columns))\n",
    "    \n",
    "    df_oldcols = df.columns.to_list()\n",
    "    df = pd.get_dummies(df, prefix_sep='_', drop_first=True)\n",
    "    \n",
    "    print('Quantity of columns after one-hot encoding:', len(df.columns))\n",
    "    \n",
    "    # rename columns to show which are dummies\n",
    "    onehot_cols = list(set(df.columns.to_list()) - set(df_oldcols))\n",
    "    onehot_cols_renaming = {col: 'dummy_'+col.replace('-', '_') for col in onehot_cols}\n",
    "    df.rename(columns = onehot_cols_renaming, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths and capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = os.path.join('..', 'data', '02_intermediate')\n",
    "outputs = os.path.join('..', 'data', '03_processed')\n",
    "reports = os.path.join('..', 'data', '06_reporting')\n",
    "\n",
    "ord_dict = {}\n",
    "ord_dict['X_train'] = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "ord_dict['X_test'] = pd.read_csv(os.path.join(inputs, 'X_test.csv'), index_col='id')\n",
    "\n",
    "onehot_dict = copy.deepcopy(ord_dict)\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id') \n",
    "y_test = pd.read_csv(os.path.join(inputs, 'y_test.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df = pd.read_csv(os.path.join(reports, 'data_types.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count categorical data unique values\n",
    "Check both train and test. Any inconsistency between them should be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "checking number of categories for X_train\n",
      "Numero de categorias para variavel 'multiplelines': 3 \n",
      "Numero de categorias para variavel 'internetservice': 3 \n",
      "Numero de categorias para variavel 'streamingtv': 3 \n",
      "Numero de categorias para variavel 'contract': 3 \n",
      "Numero de categorias para variavel 'paymentmethod': 4 \n",
      "\r\n",
      "checking number of categories for X_test\n",
      "Numero de categorias para variavel 'multiplelines': 3 \n",
      "Numero de categorias para variavel 'internetservice': 3 \n",
      "Numero de categorias para variavel 'streamingtv': 3 \n",
      "Numero de categorias para variavel 'contract': 3 \n",
      "Numero de categorias para variavel 'paymentmethod': 4 \n"
     ]
    }
   ],
   "source": [
    "for data in ['X_train', 'X_test']:\n",
    "    categories_dict = {}\n",
    "    print('\\r\\nchecking number of categories for {}'. format(data))\n",
    "    for cat in ord_dict[data].columns:\n",
    "        if ord_dict[data][cat].dtypes == 'object':\n",
    "            categories_dict[cat] = list(ord_dict[data][cat].unique())\n",
    "            print(\"Numero de categorias para variavel '{}': {} \".format(cat, ord_dict[data][cat].unique().size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_male</th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phoneservice</th>\n",
       "      <th>multiplelines</th>\n",
       "      <th>internetservice</th>\n",
       "      <th>onlinesecurity</th>\n",
       "      <th>onlinebackup</th>\n",
       "      <th>deviceprotection</th>\n",
       "      <th>techsupport</th>\n",
       "      <th>streamingtv</th>\n",
       "      <th>streamingmovies</th>\n",
       "      <th>contract</th>\n",
       "      <th>paperlessbilling</th>\n",
       "      <th>paymentmethod</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>if_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7590-vhveg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5575-gnvde</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3668-qpybk</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795-cfocw</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237-hqitu</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender_male  seniorcitizen  partner  dependents  tenure  \\\n",
       "id                                                                    \n",
       "7590-vhveg          0.0            0.0      1.0         0.0     1.0   \n",
       "5575-gnvde          1.0            0.0      0.0         0.0    34.0   \n",
       "3668-qpybk          1.0            0.0      0.0         0.0     2.0   \n",
       "7795-cfocw          1.0            0.0      0.0         0.0    45.0   \n",
       "9237-hqitu          0.0            0.0      0.0         0.0     2.0   \n",
       "\n",
       "            phoneservice  multiplelines  internetservice  onlinesecurity  \\\n",
       "id                                                                         \n",
       "7590-vhveg           0.0            0.0              0.0             0.0   \n",
       "5575-gnvde           1.0            1.0              0.0             1.0   \n",
       "3668-qpybk           1.0            1.0              0.0             1.0   \n",
       "7795-cfocw           0.0            0.0              0.0             1.0   \n",
       "9237-hqitu           1.0            1.0              1.0             0.0   \n",
       "\n",
       "            onlinebackup  deviceprotection  techsupport  streamingtv  \\\n",
       "id                                                                     \n",
       "7590-vhveg           1.0               0.0          0.0          0.0   \n",
       "5575-gnvde           0.0               1.0          0.0          0.0   \n",
       "3668-qpybk           1.0               0.0          0.0          0.0   \n",
       "7795-cfocw           0.0               1.0          1.0          0.0   \n",
       "9237-hqitu           0.0               0.0          0.0          0.0   \n",
       "\n",
       "            streamingmovies  contract  paperlessbilling  paymentmethod  \\\n",
       "id                                                                       \n",
       "7590-vhveg              0.0       0.0               1.0            0.0   \n",
       "5575-gnvde              0.0       1.0               0.0            1.0   \n",
       "3668-qpybk              0.0       0.0               1.0            1.0   \n",
       "7795-cfocw              0.0       1.0               0.0            2.0   \n",
       "9237-hqitu              0.0       0.0               1.0            0.0   \n",
       "\n",
       "            monthlycharges  totalcharges  if_anomaly  \n",
       "id                                                    \n",
       "7590-vhveg           29.85         29.85           1  \n",
       "5575-gnvde           56.95       1889.50           1  \n",
       "3668-qpybk           53.85        108.15           1  \n",
       "7795-cfocw           42.30       1840.75          -1  \n",
       "9237-hqitu           70.70        151.65           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_dict['X_train'], ord_dict['X_test'] = ordinal_encode(ord_dict['X_train'], ord_dict['X_test'], testing = False)\n",
    "\n",
    "ord_dict['X_train'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of columns before one-hot encoding: 20\n",
      "Quantity of columns after one-hot encoding: 26\n",
      "Quantity of columns before one-hot encoding: 20\n",
      "Quantity of columns after one-hot encoding: 26\n",
      "\r\n",
      "Columns of the new database:\n"
     ]
    }
   ],
   "source": [
    "for df in ['X_train', 'X_test']:\n",
    "    onehot_dict[df] = one_hot_encode(onehot_dict[df])\n",
    "    \n",
    "print('\\r\\nColumns of the new database:')\n",
    "# print(onehot_dict[df].columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# report new data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dummy_vars_df = pd.DataFrame([c for c in onehot_dict['X_train'].columns.to_list() if c.startswith('dummy')])\n",
    "report_df = pd.concat([report_df,dummy_vars_df], ignore_index=True, axis=1)\n",
    "report_df.columns = ['numerical_cols', 'non_numerical_cols', 'dummy_cols']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data alignment\n",
    "if some category is missing on test set, we need to account for that and build corresponding column filled with 'zeros'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_cols(smaller, greater):\n",
    "    missing_cols = set( greater.columns ) - set( smaller.columns )\n",
    "    for c in missing_cols:\n",
    "        smaller[c] = 0\n",
    "    \n",
    "    return smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_dict['X_train'] = fill_missing_cols(onehot_dict['X_train'], onehot_dict['X_test'])\n",
    "onehot_dict['X_test'] = fill_missing_cols(onehot_dict['X_test'], onehot_dict['X_train'])\n",
    "\n",
    "# align column positions (no data leakage here. Just altering column ordering.)\n",
    "onehot_dict['X_train'], onehot_dict['X_test'] = onehot_dict['X_train'].align(onehot_dict['X_test'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4930, 20)\n",
      "(4930, 26)\n",
      "(2113, 20)\n",
      "(2113, 26)\n"
     ]
    }
   ],
   "source": [
    "for df in ['X_train', 'X_test']:\n",
    "    ord_dict[df].to_csv(os.path.join(outputs, df+'.csv'))\n",
    "    onehot_dict[df].to_csv(os.path.join(outputs, df+'_onehot.csv'))\n",
    "    \n",
    "for df in ['X_train', 'X_test']:\n",
    "    print(ord_dict[df].shape)\n",
    "    print(onehot_dict[df].shape)\n",
    "    \n",
    "y_train.to_csv(os.path.join(outputs, 'y_train.csv'))\n",
    "y_test.to_csv(os.path.join(outputs, 'y_test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save report over data types"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "report_df.to_csv(os.path.join(reports, 'data_types.csv'), index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
